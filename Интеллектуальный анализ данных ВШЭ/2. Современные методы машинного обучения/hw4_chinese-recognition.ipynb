{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332987, 2)\n"
     ]
    }
   ],
   "source": [
    "data_train = np.load(\"../input/chinese-char-recognition-smmo19/train-1.npy\", allow_pickle=True)\n",
    "data_test = np.load('../input/chinese-char-recognition-smmo19/test.npy', allow_pickle=True)\n",
    "#np.random.shuffle(data_train)\n",
    "for i in range(2, 5):\n",
    "    t = np.load(f\"../input/chinese-char-recognition-smmo19/train-{i}.npy\", allow_pickle=True)\n",
    "    data_train = np.concatenate([data_train, t])\n",
    "    \n",
    "IMG_SIZE = 80\n",
    "DATASET_SIZE = len(data_train)\n",
    "batch_size = 128\n",
    "val_size = 0.1\n",
    "\n",
    "tokens = np.unique([v[1] for v in data_train])\n",
    "id_to_char = {id:char for id, char in enumerate(tokens)}\n",
    "char_to_id = {char:id for id, char in enumerate(tokens)}\n",
    "\n",
    "print(data_train.shape)\n",
    "data_train = data_train.tolist()\n",
    "\n",
    "def train_gen():\n",
    "    for img, label in data_train[int(len(data_train)*val_size):]:\n",
    "        img = img[..., None] # [batch, w, h, channels]\n",
    "        yield img, char_to_id[label] #char_to_vector[]\n",
    "\n",
    "def val_gen():\n",
    "    for img, label in data_train[:int(len(data_train)*val_size)]:\n",
    "        img = img[..., None] # [batch, w, h, channels]\n",
    "        yield img, char_to_id[label] \n",
    "\n",
    "def test_gen():\n",
    "    for img in data_test:\n",
    "        img = img[..., None] # [batch, w, h, channels]\n",
    "        yield img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image):\n",
    "    number = np.random.random_sample()\n",
    "    if 0.5 <= number :\n",
    "        image = flip(image)\n",
    "        image = zoom(image)\n",
    "        image = color(image)\n",
    "    return image\n",
    "\n",
    "def flip(x: tf.Tensor) -> tf.Tensor:\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "\n",
    "def color(x: tf.Tensor) -> tf.Tensor:\n",
    "    x = tf.image.random_hue(x, 0.08)\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
    "    x = tf.image.random_brightness(x, 0.05)\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
    "    return x\n",
    "\n",
    "def zoom(x: tf.Tensor) -> tf.Tensor:\n",
    "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
    "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
    "    boxes = np.zeros((len(scales), 4))\n",
    "    for i, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - (0.5 * scale)\n",
    "        x2 = y2 = 0.5 + (0.5 * scale)\n",
    "        boxes[i] = [x1, y1, x2, y2]\n",
    "\n",
    "    def random_crop(img):\n",
    "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(32, 32))\n",
    "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
    "\n",
    "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "    # Only apply cropping 50% of the time\n",
    "    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(image, label):\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = augmentation(image)\n",
    "    image = tf.cast(image, tf.float32)/ 127.5 - 1\n",
    "    image = preprocess_input(image)\n",
    "    label = tf.one_hot(label, 1000)\n",
    "    return image, label\n",
    "\n",
    "def preprocess_val(image, label):\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "    image = preprocess_input(image)\n",
    "    label = tf.one_hot(label, 1000)\n",
    "    return image, label\n",
    "\n",
    "def preprocess_test(image):\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32)/ 127.5 - 1\n",
    "    image = preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_generator(train_gen,\n",
    "                                          output_types=(tf.float32, tf.int32), \n",
    "                                          output_shapes=((None,None,1), ())).map(preprocess_train, tf.data.experimental.AUTOTUNE).prefetch(-1).shuffle(1000).batch(batch_size).repeat()\n",
    "\n",
    "ds_val = tf.data.Dataset.from_generator(val_gen,\n",
    "                                          output_types=(tf.float32, tf.int32), \n",
    "                                          output_shapes=((None,None,1), ())).map(preprocess_val, tf.data.experimental.AUTOTUNE).prefetch(-1).shuffle(1000).batch(batch_size).repeat()\n",
    "\n",
    "ds_test = tf.data.Dataset.from_generator(test_gen,\n",
    "                                          output_types=(tf.float32), \n",
    "                                          output_shapes=((None,None,1))\n",
    "                                          ).map(preprocess_test, tf.data.experimental.AUTOTUNE).prefetch(-1).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приступим к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 40\n",
    "steps_per_epoch = round(len(data_train))//(batch_size*10)\n",
    "validation_steps = round(len(data_train)*val_size)//(batch_size*10)\n",
    "\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 1)\n",
    "INIT_LR = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "#from keras.applications import VGG19\n",
    "# from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tensorflow.keras.applications.xception.Xception(weights=None,\n",
    "                                               input_shape=IMG_SHAPE, \n",
    "                                               classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    return INIT_LR * 0.9 ** epoch\n",
    "\n",
    "base_model.compile(\n",
    "        loss= 'categorical_crossentropy',\n",
    "        optimizer= tf.keras.optimizers.Adam(lr=INIT_LR),\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Begin training at 2019-12-23 16:54:00.977815\n",
      "Train for 2500 steps, validate for 200 steps\n",
      "Epoch 1/15\n",
      "2500/2500 [==============================] - 486s 194ms/step - loss: 1.6626 - accuracy: 0.6562 - val_loss: 64.1313 - val_accuracy: 0.0015\n",
      "Epoch 2/15\n",
      "2500/2500 [==============================] - 478s 191ms/step - loss: 0.1527 - accuracy: 0.9555 - val_loss: 79.9647 - val_accuracy: 9.3750e-04\n",
      "Epoch 3/15\n",
      "2500/2500 [==============================] - 478s 191ms/step - loss: 0.0831 - accuracy: 0.9749 - val_loss: 79.4770 - val_accuracy: 9.3750e-04\n",
      "Epoch 4/15\n",
      "2500/2500 [==============================] - 478s 191ms/step - loss: 0.0498 - accuracy: 0.9848 - val_loss: 33.5277 - val_accuracy: 9.3750e-04\n",
      "Epoch 5/15\n",
      "2500/2500 [==============================] - 477s 191ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 6962.7984 - val_accuracy: 8.9844e-04\n",
      "Epoch 6/15\n",
      "2500/2500 [==============================] - 479s 192ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 35.4932 - val_accuracy: 9.3750e-04\n",
      "Epoch 15/15\n",
      " 870/2500 [=========>....................] - ETA: 5:04 - loss: 0.0015 - accuracy: 0.9996"
     ]
    }
   ],
   "source": [
    "print(f'>> Begin training at {datetime.datetime.now()}')\n",
    "base_model.fit(ds_train,epochs=15,\n",
    "                  validation_data = ds_val,\n",
    "                   steps_per_epoch=2500,\n",
    "                   validation_steps=200, verbose = 1, \n",
    "                    callbacks = [tf.keras.callbacks.ModelCheckpoint('weights1.{epoch:02d}.hdf5', best_only=True, monitor='accuracy', period = 10),\n",
    "                                 tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "                  ])\n",
    "print(f'>> Training finished at {datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Begin training at 2019-12-23 18:53:51.291480\n",
      "Train for 2000 steps, validate for 100 steps\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 381s 190ms/step - loss: 0.0587 - accuracy: 0.9831 - val_loss: 50.1197 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 380s 190ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 136.5429 - val_accuracy: 0.0015\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 381s 190ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 39.3473 - val_accuracy: 0.0020\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 379s 190ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 21.6367 - val_accuracy: 0.0021\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 380s 190ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 32.6523 - val_accuracy: 0.0011\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 379s 190ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 31.4287 - val_accuracy: 0.0013\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 379s 189ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 7.8275 - val_accuracy: 0.1188\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 380s 190ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 27.0724 - val_accuracy: 0.0027\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 381s 190ms/step - loss: 3.4196e-04 - accuracy: 0.9999 - val_loss: 8.7440e-04 - val_accuracy: 0.9998\n",
      ">> Training finished at 2019-12-23 21:00:33.147896\n"
     ]
    }
   ],
   "source": [
    "print(f'>> Begin training at {datetime.datetime.now()}')\n",
    "base_model.fit(ds_train,epochs=20,\n",
    "                  validation_data = ds_val,\n",
    "                   steps_per_epoch=2000,\n",
    "                   validation_steps=100, verbose = 1, \n",
    "                    callbacks = [tf.keras.callbacks.ModelCheckpoint('weights2.{epoch:02d}.hdf5', best_only=True, monitor='accuracy', period = 5),\n",
    "                                 tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "                  ])\n",
    "print(f'>> Training finished at {datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.evaluate(ds_val, verbose= 1, steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Begin prediction at 2019-12-23 21:00:40.266660\n",
      "    651/Unknown - 32s 49ms/step>> Finished prediction at 2019-12-23 21:01:12.478192\n"
     ]
    }
   ],
   "source": [
    "print(f'>> Begin prediction at {datetime.datetime.now()}')\n",
    "result = base_model.predict(ds_test, verbose=1)\n",
    "predictions_without_cat = result.argmax(-1) #[np.argmax(predict) for predict in result] \n",
    "predictions = [id_to_char[predict] for predict in predictions_without_cat]\n",
    "print(f'>> Finished prediction at {datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/chinese-char-recognition-smmo19/random_labels.csv')\n",
    "df['Category'] = predictions\n",
    "df.to_csv('submission.csv', index=False)\n",
    "np.savetxt(\"submision_please_do_it.csv\", predictions, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.applications\n",
    "# from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "#from tensorflow.keras.applications.xception import preprocess_input\n",
    "#from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
